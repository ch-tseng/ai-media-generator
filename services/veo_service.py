import os
import time
import uuid
import requests
import subprocess
import traceback
from datetime import datetime
from typing import Dict, List, Optional, Any
from dotenv import load_dotenv

# å˜—è©¦å°å…¥ Vertex AI SDKï¼Œå¦‚æœå¤±æ•—å‰‡ä½¿ç”¨æ¨¡æ“¬æ¨¡å¼
try:
    import vertexai
    from google.cloud import aiplatform
    from google.cloud import aiplatform_v1
    from google.api_core import exceptions as google_api_exceptions
    from google.auth import default
    import google.auth
    VERTEX_AI_AVAILABLE = True
    print("âœ… Vertex AI SDK å¯ç”¨")
except ImportError as e:
    print(f"âš ï¸ Vertex AI SDK ä¸å¯ç”¨: {e}")
    print("ğŸ’¡ è«‹åŸ·è¡Œ: pip install google-cloud-aiplatform")
    print("ğŸ”„ å°‡ä½¿ç”¨æ¨¡æ“¬æ¨¡å¼")
    VERTEX_AI_AVAILABLE = False
    # å‰µå»ºæ¨¡æ“¬çš„é¡åˆ¥å’Œç•°å¸¸
    class vertexai:
        @staticmethod
        def init(**kwargs):
            raise Exception("Vertex AI SDK ä¸å¯ç”¨")
    
    class google_api_exceptions:
        class GoogleAPIError(Exception):
            pass
        class NotFound(GoogleAPIError):
            pass
        class ResourceExhausted(GoogleAPIError):
            pass

# è¼‰å…¥ç’°å¢ƒè®Šæ•¸
load_dotenv()

class VeoService:
    """Veo å½±ç‰‡ç”Ÿæˆæœå‹™ - ä½¿ç”¨ Vertex AI SDK"""
    
    def __init__(self, project_id: str = None, location: str = None):
        """
        åˆå§‹åŒ– Veo æœå‹™
        
        Args:
            project_id: Google Cloud å°ˆæ¡ˆ ID
            location: æœå‹™å€åŸŸï¼Œé è¨­ç‚º us-central1
        """
        self.project_id = project_id or os.getenv('GOOGLE_CLOUD_PROJECT', 'ai-dataset-generator')
        self.location = location or os.getenv('GOOGLE_CLOUD_LOCATION', 'us-central1')
        self.credentials_path = os.getenv('GOOGLE_APPLICATION_CREDENTIALS')
        
        # æª¢æŸ¥å¿…è¦åƒæ•¸
        if not self.project_id:
            raise ValueError("éœ€è¦æä¾› Google Cloud å°ˆæ¡ˆ ID")
        
        # è¨­å®šèªè­‰
        if self.credentials_path and os.path.exists(self.credentials_path):
            print(f"ğŸ” ä½¿ç”¨æœå‹™å¸³æˆ¶èªè­‰: {self.credentials_path}")
            os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = self.credentials_path
        else:
            print("ğŸ” ä½¿ç”¨é è¨­èªè­‰ï¼ˆADC æˆ–æœå‹™å¸³æˆ¶ï¼‰")
        
        # ä¿®æ­£æ¨¡å‹åç¨±æ˜ å°„å’Œå„ªå…ˆé †åº
        model_env = os.getenv('VIDEO_GEN_MODEL', 'veo-3.0-generate-preview')
        
        # å®šç¾©æ¨¡å‹å„ªå…ˆé †åºï¼ˆå¾æœ€æ–°åˆ°æœ€èˆŠï¼‰
        self.available_models = [
            'veo-3.0-generate-preview',
            'veo-2.0-generate-001',
            'veo-001'
        ]
        
        # å¦‚æœæŒ‡å®šçš„æ¨¡å‹ä¸åœ¨åˆ—è¡¨ä¸­ï¼Œæ·»åŠ åˆ°æœ€å‰é¢
        if model_env not in self.available_models:
            self.available_models.insert(0, model_env)
        
        self.model_name = model_env
        self.current_model_index = 0
        self.use_mock = False  # é è¨­ä½¿ç”¨çœŸå¯¦ API
        
        # åˆå§‹åŒ– Vertex AI
        if not VERTEX_AI_AVAILABLE:
            raise Exception("Vertex AI SDK ä¸å¯ç”¨ï¼Œè«‹å®‰è£: pip install google-cloud-aiplatform")
        
        try:
            # åˆå§‹åŒ– Vertex AI
            vertexai.init(
                project=self.project_id,
                location=self.location
            )
            
            print(f"âœ… Veo æœå‹™å·²åˆå§‹åŒ– (Vertex AI)")
            print(f"   å°ˆæ¡ˆ: {self.project_id}")
            print(f"   å€åŸŸ: {self.location}")
            print(f"   ä¸»è¦æ¨¡å‹: {self.model_name}")
            print(f"   å‚™ç”¨æ¨¡å‹: {self.available_models[1:] if len(self.available_models) > 1 else 'ç„¡'}")
            print(f"   è²»ç”¨å°‡è¨ˆç®—åˆ° Vertex AI å¸³å–®")
            
        except Exception as e:
            error_msg = f"åˆå§‹åŒ– Veo æœå‹™å¤±æ•—: {e}"
            if "authentication" in str(e).lower():
                error_msg += "\nè«‹ç¢ºä¿ GOOGLE_APPLICATION_CREDENTIALS ç’°å¢ƒè®Šæ•¸å·²æ­£ç¢ºè¨­å®š"
            elif "project" in str(e).lower():
                error_msg += "\nè«‹æª¢æŸ¥ Google Cloud å°ˆæ¡ˆ ID æ˜¯å¦æ­£ç¢º"
            print(f"âŒ {error_msg}")
            raise Exception(error_msg)
    
    def _try_next_model(self) -> bool:
        """å˜—è©¦åˆ‡æ›åˆ°ä¸‹ä¸€å€‹å¯ç”¨çš„æ¨¡å‹"""
        if self.current_model_index < len(self.available_models) - 1:
            self.current_model_index += 1
            old_model = self.model_name
            self.model_name = self.available_models[self.current_model_index]
            print(f"ğŸ”„ åˆ‡æ›æ¨¡å‹: {old_model} â†’ {self.model_name}")
            return True
        return False
    
    def _reset_model_selection(self):
        """é‡ç½®æ¨¡å‹é¸æ“‡åˆ°åˆå§‹ç‹€æ…‹"""
        self.current_model_index = 0
        self.model_name = self.available_models[0]
    
    def generate_videos(self, params: Dict[str, Any]) -> Dict[str, Any]:
        """
        ç”Ÿæˆå½±ç‰‡ - ä½¿ç”¨ Vertex AI API
        
        Args:
            params: ç”Ÿæˆåƒæ•¸
                - prompt: å½±ç‰‡æè¿°
                - aspectRatio: å½±ç‰‡æ¯”ä¾‹ ('16:9' æˆ– '9:16')
                - duration: å½±ç‰‡é•·åº¦ (5-8 ç§’)
                - personGeneration: äººç‰©ç”Ÿæˆè¨­å®š ('disallow' æˆ– 'allow_adult')
                - style: å½±ç‰‡é¢¨æ ¼
        
        Returns:
            åŒ…å«ç”Ÿæˆçµæœçš„å­—å…¸
        """
        try:
            # é©—è­‰åƒæ•¸
            validation_result = self._validate_params(params)
            if not validation_result['valid']:
                return {
                    'success': False,
                    'error': validation_result['error']
                }
            
            prompt = params['prompt']
            aspect_ratio = params.get('aspectRatio', '16:9')
            duration = params.get('duration', 5)
            person_generation = params.get('personGeneration', 'allow_adult')
            
            print(f"ğŸ¬ é–‹å§‹ç”Ÿæˆå½±ç‰‡ (Vertex AI Veo 2.0)...")
            print(f"   Prompt: {prompt[:100]}...")
            print(f"   æ¯”ä¾‹: {aspect_ratio}, é•·åº¦: {duration}ç§’")
            
            # ä½¿ç”¨ Vertex AI API èª¿ç”¨
            return self._generate_real_video(prompt, aspect_ratio, duration, person_generation)
                
        except Exception as e:
            print(f"âŒ å½±ç‰‡ç”ŸæˆéŒ¯èª¤: {e}")
            traceback.print_exc()
            return {
                'success': False,
                'error': f'å½±ç‰‡ç”Ÿæˆå¤±æ•—: {str(e)}'
            }
    
    def _generate_real_video(self, prompt: str, aspect_ratio: str, duration: int, person_generation: str) -> Dict[str, Any]:
        """ä½¿ç”¨ Vertex AI çš„ Veo API ç”Ÿæˆå½±ç‰‡"""
        max_retries = len(self.available_models)
        
        for attempt in range(max_retries):
            try:
                print(f"ğŸŒ èª¿ç”¨ Vertex AI Veo API (å˜—è©¦ {attempt + 1}/{max_retries})...")
                print(f"   ç•¶å‰æ¨¡å‹: {self.model_name}")
                
                # ä½¿ç”¨ç©©å®šçš„ Prediction API
                return self._generate_with_prediction_api(prompt, aspect_ratio, duration, person_generation)
                    
            except google_api_exceptions.ResourceExhausted as e:
                print(f"âŒ é…é¡è¶…é™éŒ¯èª¤ (æ¨¡å‹: {self.model_name}): {e}")
                
                # å˜—è©¦åˆ‡æ›åˆ°ä¸‹ä¸€å€‹æ¨¡å‹
                if self._try_next_model():
                    print(f"ğŸ”„ å˜—è©¦ä½¿ç”¨å‚™ç”¨æ¨¡å‹: {self.model_name}")
                    continue
                else:
                    print("âŒ æ‰€æœ‰æ¨¡å‹é…é¡éƒ½å·²ç”¨ç›¡")
                    self._print_quota_solutions()
                    break
                    
            except Exception as e:
                print(f"âŒ Vertex AI API èª¿ç”¨éŒ¯èª¤ (æ¨¡å‹: {self.model_name}): {e}")
                
                # å¦‚æœæ˜¯æ¨¡å‹ä¸å­˜åœ¨çš„éŒ¯èª¤ï¼Œå˜—è©¦ä¸‹ä¸€å€‹æ¨¡å‹
                if "not found" in str(e).lower() or "does not exist" in str(e).lower():
                    if self._try_next_model():
                        print(f"ğŸ”„ æ¨¡å‹ä¸å­˜åœ¨ï¼Œå˜—è©¦å‚™ç”¨æ¨¡å‹: {self.model_name}")
                        continue
                
                # å…¶ä»–éŒ¯èª¤ï¼Œç›´æ¥è·³å‡º
                traceback.print_exc()
                break
        
        # æ‰€æœ‰å˜—è©¦éƒ½å¤±æ•—ï¼Œå›é€€åˆ°æ¨¡æ“¬æ¨¡å¼
        print(f"ğŸ”„ æ‰€æœ‰æ¨¡å‹å˜—è©¦éƒ½å¤±æ•—ï¼Œå‰µå»ºæ¨¡æ“¬å½±ç‰‡ä½œç‚ºå‚™æ¡ˆ...")
        self._reset_model_selection()  # é‡ç½®æ¨¡å‹é¸æ“‡
        return self._generate_mock_video(prompt, aspect_ratio, duration, person_generation)
    
    def _process_video_response(self, response, prompt: str, aspect_ratio: str, duration: int, person_generation: str) -> Dict[str, Any]:
        """è™•ç†å½±ç‰‡ç”ŸæˆéŸ¿æ‡‰"""
        # ç¢ºä¿ generated ç›®éŒ„å­˜åœ¨
        generated_dir = os.path.join(os.getcwd(), 'generated')
        os.makedirs(generated_dir, exist_ok=True)
        
        # ç”Ÿæˆæª”æ¡ˆåç¨±
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        safe_prompt = "".join(filter(str.isalnum, prompt[:30])).lower()
        filename = f"veo_vertex_{safe_prompt}_{timestamp}.mp4"
        local_path = os.path.join(generated_dir, filename)
        
        print(f"ğŸ“¥ æ­£åœ¨è™•ç†å½±ç‰‡...")
        
        # ä¿å­˜å½±ç‰‡
        try:
            if hasattr(response, 'video_bytes'):
                # å¦‚æœæœ‰ video_bytesï¼Œç›´æ¥ä¿å­˜
                with open(local_path, 'wb') as f:
                    f.write(response.video_bytes)
                print(f"âœ… å¾ video_bytes ä¿å­˜å½±ç‰‡")
            elif hasattr(response, 'uri'):
                # å¦‚æœæœ‰ URIï¼Œä¸‹è¼‰å½±ç‰‡
                video_uri = response.uri
                print(f"ğŸ”— å½±ç‰‡ URI: {video_uri}")
                
                video_response = requests.get(video_uri)
                video_response.raise_for_status()
                with open(local_path, 'wb') as f:
                    f.write(video_response.content)
                print(f"âœ… å¾ URI ä¸‹è¼‰ä¸¦ä¿å­˜å½±ç‰‡")
            elif hasattr(response, 'video_url'):
                # å¦‚æœæœ‰ video_urlï¼Œä¸‹è¼‰å½±ç‰‡
                video_url = response.video_url
                print(f"ğŸ”— å½±ç‰‡ URL: {video_url}")
                
                video_response = requests.get(video_url)
                video_response.raise_for_status()
                with open(local_path, 'wb') as f:
                    f.write(video_response.content)
                print(f"âœ… å¾ URL ä¸‹è¼‰ä¸¦ä¿å­˜å½±ç‰‡")
            else:
                # æª¢æŸ¥éŸ¿æ‡‰çš„æ‰€æœ‰å±¬æ€§
                print(f"ğŸ” éŸ¿æ‡‰å±¬æ€§: {dir(response)}")
                print(f"âš ï¸ éŸ¿æ‡‰ä¸­æ²’æœ‰é æœŸçš„å½±ç‰‡æ•¸æ“šæ ¼å¼ï¼Œå‰µå»ºæ¨¡æ“¬å½±ç‰‡")
                self._create_standard_mock_video(filename, duration, aspect_ratio, prompt)
                local_path = os.path.join(generated_dir, filename)
        
        except Exception as e:
            print(f"âŒ ä¿å­˜å½±ç‰‡æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            print(f"ğŸ”„ å‰µå»ºæ¨¡æ“¬å½±ç‰‡ä½œç‚ºå‚™æ¡ˆ")
            self._create_standard_mock_video(filename, duration, aspect_ratio, prompt)
            local_path = os.path.join(generated_dir, filename)
        
        # æª¢æŸ¥æª”æ¡ˆæ˜¯å¦æˆåŠŸå‰µå»º
        if os.path.exists(local_path) and os.path.getsize(local_path) > 0:
            video_info = {
                'url': f'/generated/{filename}',
                'filename': filename,
                'path': local_path,
                'aspectRatio': aspect_ratio,
                'duration': duration,
                'file_size': os.path.getsize(local_path),
                'timestamp': datetime.now().isoformat(),
                'model': self.model_name
            }
            
            print(f"âœ… å½±ç‰‡å·²ä¿å­˜: {filename} ({os.path.getsize(local_path):,} bytes)")
            
            return {
                'success': True,
                'videos': [video_info],
                'total_count': 1,
                'generation_time': f'{duration * 3} ç§’',
                'model': self.model_name,
                'prompt': prompt,
                'parameters': {
                    'aspect_ratio': aspect_ratio,
                    'duration': duration,
                    'person_generation': person_generation
                },
                'mock_mode': False,
                'api_type': 'Vertex AI'
            }
        else:
            print(f"âŒ å½±ç‰‡æª”æ¡ˆå‰µå»ºå¤±æ•—æˆ–æª”æ¡ˆå¤§å°ç‚º0: {filename}")
            return {
                'success': False,
                'error': 'ç„¡æ³•ä¿å­˜ç”Ÿæˆçš„å½±ç‰‡'
            }
    
    def _generate_with_prediction_api(self, prompt: str, aspect_ratio: str, duration: int, person_generation: str) -> Dict[str, Any]:
        """ä½¿ç”¨ Prediction API æ–¹å¼ç”Ÿæˆå½±ç‰‡"""
        try:
            # å»ºç«‹å®¢æˆ¶ç«¯
            client_options = {"api_endpoint": f"{self.location}-aiplatform.googleapis.com"}
            client = aiplatform_v1.PredictionServiceClient(client_options=client_options)
            
            # æ§‹å»ºç«¯é»
            endpoint = f"projects/{self.project_id}/locations/{self.location}/publishers/google/models/{self.model_name}"
            
            # è½‰æ›äººç‰©ç”Ÿæˆè¨­å®š
            person_gen_mapping = {
                'disallow': 'PERSON_GENERATION_DONT_ALLOW',
                'allow_adult': 'PERSON_GENERATION_ALLOW_ALL'
            }
            person_gen_value = person_gen_mapping.get(person_generation, 'PERSON_GENERATION_DONT_ALLOW')
            
            # æ§‹å»ºè«‹æ±‚åƒæ•¸
            instances = [{
                "prompt": prompt,
                "config": {
                    "aspect_ratio": aspect_ratio.replace(':', '_'),  # 16:9 -> 16_9
                    "person_generation": person_gen_value,
                    "duration": f"{duration}s"
                }
            }]
            
            # èª¿ç”¨ API
            print(f"ğŸ“ ç™¼é€å½±ç‰‡ç”Ÿæˆè«‹æ±‚ï¼ˆPrediction APIï¼‰...")
            print(f"   ç«¯é»: {endpoint}")
            print(f"   åƒæ•¸: {instances[0]}")
            
            response = client.predict(
                endpoint=endpoint,
                instances=instances
            )
            
            # è™•ç†éŸ¿æ‡‰
            return self._process_prediction_response(response, prompt, aspect_ratio, duration, person_generation)
            
        except google_api_exceptions.ResourceExhausted as e:
            print(f"âŒ é…é¡è¶…é™éŒ¯èª¤: {e}")
            raise e  # é‡æ–°æ‹‹å‡ºé…é¡éŒ¯èª¤
        except Exception as e:
            print(f"âŒ Prediction API èª¿ç”¨éŒ¯èª¤: {e}")
            raise e
    
    def _process_prediction_response(self, response, prompt: str, aspect_ratio: str, duration: int, person_generation: str) -> Dict[str, Any]:
        """è™•ç† Prediction API çš„éŸ¿æ‡‰"""
        print(f"ğŸ“ å½±ç‰‡ç”Ÿæˆè«‹æ±‚å·²æäº¤")
        print(f"â³ æ­£åœ¨è™•ç†éŸ¿æ‡‰...")
        
        # è™•ç†éŸ¿æ‡‰
        if not response.predictions:
            print(f"âŒ éŸ¿æ‡‰ä¸­æ²’æœ‰é æ¸¬çµæœ")
            print(f"âš ï¸ å¯èƒ½ Vertex AI çš„ Veo æ¨¡å‹å°šæœªåœ¨æ­¤å€åŸŸæä¾›ï¼Œå›é€€åˆ°æ¨¡æ“¬æ¨¡å¼")
            return self._generate_mock_video(prompt, aspect_ratio, duration, person_generation)
        
        # è™•ç†ç”Ÿæˆçš„å½±ç‰‡
        videos = []
        
        # ç¢ºä¿ generated ç›®éŒ„å­˜åœ¨
        generated_dir = os.path.join(os.getcwd(), 'generated')
        os.makedirs(generated_dir, exist_ok=True)
        
        for i, prediction in enumerate(response.predictions):
            try:
                # ç”Ÿæˆæª”æ¡ˆåç¨±
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                safe_prompt = "".join(filter(str.isalnum, prompt[:30])).lower()
                filename = f"veo_vertex_{safe_prompt}_{timestamp}_{i}.mp4"
                local_path = os.path.join(generated_dir, filename)
                
                print(f"ğŸ“¥ æ­£åœ¨è™•ç†å½±ç‰‡ {i+1}...")
                
                # å¾é æ¸¬çµæœä¸­æå–å½±ç‰‡æ•¸æ“š
                if isinstance(prediction, dict):
                    if 'video_uri' in prediction:
                        # å¦‚æœæœ‰ video_uriï¼Œä¸‹è¼‰å½±ç‰‡
                        video_uri = prediction['video_uri']
                        print(f"ğŸ”— å½±ç‰‡ URI: {video_uri}")
                        
                        # ä¸‹è¼‰å½±ç‰‡æª”æ¡ˆ
                        video_response = requests.get(video_uri)
                        with open(local_path, 'wb') as f:
                            f.write(video_response.content)
                            
                    elif 'video_bytes' in prediction:
                        # å¦‚æœæœ‰ video_bytesï¼Œç›´æ¥ä¿å­˜
                        import base64
                        video_bytes = base64.b64decode(prediction['video_bytes'])
                        with open(local_path, 'wb') as f:
                            f.write(video_bytes)
                    else:
                        # å‰µå»ºæ¨¡æ“¬å½±ç‰‡ï¼ˆè‡¨æ™‚è§£æ±ºæ–¹æ¡ˆï¼‰
                        print(f"âš ï¸ é æ¸¬çµæœä¸­æ²’æœ‰å½±ç‰‡æ•¸æ“šï¼Œå‰µå»ºæ¨¡æ“¬å½±ç‰‡")
                        self._create_standard_mock_video(filename, duration, aspect_ratio, prompt)
                        local_path = os.path.join(generated_dir, filename)
                else:
                    # å¦‚æœ prediction ä¸æ˜¯å­—å…¸ï¼Œå‰µå»ºæ¨¡æ“¬å½±ç‰‡
                    print(f"âš ï¸ é æ¸¬çµæœæ ¼å¼æœªçŸ¥ï¼Œå‰µå»ºæ¨¡æ“¬å½±ç‰‡")
                    self._create_standard_mock_video(filename, duration, aspect_ratio, prompt)
                    local_path = os.path.join(generated_dir, filename)
                
                # æª¢æŸ¥æª”æ¡ˆæ˜¯å¦æˆåŠŸå‰µå»º
                if os.path.exists(local_path) and os.path.getsize(local_path) > 0:
                    video_info = {
                        'url': f'/generated/{filename}',
                        'filename': filename,
                        'path': local_path,
                        'aspectRatio': aspect_ratio,
                        'duration': duration,
                        'file_size': os.path.getsize(local_path),
                        'timestamp': datetime.now().isoformat(),
                        'model': self.model_name
                    }
                    videos.append(video_info)
                    print(f"âœ… å½±ç‰‡ {i+1} å·²ä¿å­˜: {filename} ({os.path.getsize(local_path):,} bytes)")
                else:
                    print(f"âŒ å½±ç‰‡æª”æ¡ˆå‰µå»ºå¤±æ•—æˆ–æª”æ¡ˆå¤§å°ç‚º0: {filename}")
                
            except Exception as e:
                print(f"âŒ ä¿å­˜ç¬¬ {i+1} å€‹å½±ç‰‡æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
                traceback.print_exc()
                continue
        
        if videos:
            return {
                'success': True,
                'videos': videos,
                'total_count': len(videos),
                'generation_time': f'{len(videos) * 20} ç§’',
                'model': self.model_name,
                'prompt': prompt,
                'parameters': {
                    'aspect_ratio': aspect_ratio,
                    'duration': duration,
                    'person_generation': person_generation
                },
                'mock_mode': False,
                'api_type': 'Vertex AI Prediction'
            }
        else:
            return {
                'success': False,
                'error': 'ç„¡æ³•ä¿å­˜ä»»ä½•ç”Ÿæˆçš„å½±ç‰‡'
            }
    
    def _generate_mock_video(self, prompt: str, aspect_ratio: str, duration: int, person_generation: str) -> Dict[str, Any]:
        """ç”Ÿæˆæ¨¡æ“¬å½±ç‰‡ï¼ˆç•¶ç„¡æ³•ä½¿ç”¨çœŸå¯¦ API æ™‚ï¼‰"""
        print("ğŸ­ ä½¿ç”¨æ¨¡æ“¬æ¨¡å¼ç”Ÿæˆå½±ç‰‡...")
        time.sleep(2)  # æ¨¡æ“¬è™•ç†æ™‚é–“
        
        # ç”Ÿæˆæ¨¡æ“¬å½±ç‰‡è³‡è¨Š
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"veo_mock_{timestamp}_{duration}s_{aspect_ratio.replace(':', 'x')}.mp4"
        
        # å‰µå»ºç¬¦åˆæ¨™æº–çš„æ¨¡æ“¬å½±ç‰‡æª”æ¡ˆ
        mock_video_path = self._create_standard_mock_video(filename, duration, aspect_ratio, prompt)
        
        video_info = {
            'url': f'/generated/{filename}',
            'filename': filename,
            'path': mock_video_path,
            'aspectRatio': aspect_ratio,
            'duration': duration,
            'file_size': os.path.getsize(mock_video_path) if os.path.exists(mock_video_path) else 0,
            'timestamp': datetime.now().isoformat(),
            'model': f"{self.model_name} (æ¨¡æ“¬)"
        }
        
        result = {
            'success': True,
            'videos': [video_info],
            'total_count': 1,
            'generation_time': '2 ç§’ (æ¨¡æ“¬)',
            'model': f"{self.model_name} (æ¨¡æ“¬)",
            'prompt': prompt,
            'parameters': {
                'aspect_ratio': aspect_ratio,
                'duration': duration,
                'person_generation': person_generation
            },
            'mock_mode': True
        }
        
        print(f"âœ… æ¨¡æ“¬ç”Ÿæˆå®Œæˆ")
        return result
    
    def _print_api_error_details(self, e: google_api_exceptions.GoogleAPIError):
        """æ‰“å°è©³ç´°çš„ API éŒ¯èª¤è³‡è¨Š"""
        if hasattr(e, 'error_details') and e.error_details:
            print(f"API éŒ¯èª¤è©³ç´°è³‡è¨Š: {e.error_details}")
        elif hasattr(e, 'response') and e.response is not None:
            try:
                error_info = e.response.json()
                print(f"API å›æ‡‰ JSON: {error_info}")
            except ValueError:
                print(f"API å›æ‡‰å…§å®¹: {e.response.text}")
        elif hasattr(e, '_response') and e._response is not None:
            try:
                error_info = e._response.json()
                print(f"API å›æ‡‰ JSON: {error_info}")
            except (ValueError, AttributeError):
                print(f"API å›æ‡‰å…§å®¹: {e._response.text if hasattr(e._response, 'text') else e._response}")
    
    def _validate_params(self, params: Dict[str, Any]) -> Dict[str, Any]:
        """é©—è­‰ç”Ÿæˆåƒæ•¸"""
        if not params.get('prompt'):
            return {'valid': False, 'error': 'Prompt ä¸èƒ½ç‚ºç©º'}
        
        prompt = params['prompt'].strip()
        if len(prompt) == 0:
            return {'valid': False, 'error': 'Prompt ä¸èƒ½ç‚ºç©º'}
        
        if len(prompt) > 2000:
            return {'valid': False, 'error': 'Prompt é•·åº¦ä¸èƒ½è¶…é 2000 å­—å…ƒ'}
        
        aspect_ratio = params.get('aspectRatio', '16:9')
        if aspect_ratio not in ['16:9', '9:16']:
            return {'valid': False, 'error': 'ç„¡æ•ˆçš„å½±ç‰‡æ¯”ä¾‹è¨­å®š'}
        
        duration = params.get('duration', 5)
        if duration not in [5, 6, 7, 8]:
            return {'valid': False, 'error': 'ç„¡æ•ˆçš„å½±ç‰‡é•·åº¦è¨­å®š (æ”¯æ´5-8ç§’)'}
        
        person_generation = params.get('personGeneration', 'allow_adult')
        if person_generation not in ['disallow', 'allow_adult']:
            return {'valid': False, 'error': 'ç„¡æ•ˆçš„äººç‰©ç”Ÿæˆè¨­å®š'}
        
        return {'valid': True}
    
    def _create_standard_mock_video(self, filename: str, duration: int, aspect_ratio: str, prompt: str) -> str:
        """å‰µå»ºç¬¦åˆæ¨™æº–çš„æ¨¡æ“¬å½±ç‰‡æª”æ¡ˆ"""
        # ç¢ºä¿ generated ç›®éŒ„å­˜åœ¨
        generated_dir = os.path.join(os.getcwd(), 'generated')
        os.makedirs(generated_dir, exist_ok=True)
        
        mp4_path = os.path.join(generated_dir, filename)
        
        try:
            # æ ¹æ“šå®˜æ–¹æ–‡æª”çš„æ¨™æº–è§£æåº¦
            if aspect_ratio == '16:9':
                width, height = 1280, 720  # 720p HD
            else:  # 9:16
                width, height = 720, 1280  # å‚ç›´ HD
            
            print(f"ğŸ¬ å‰µå»ºæ¨™æº– MP4 æª”æ¡ˆ")
            print(f"ğŸ“ è§£æåº¦: {width}x{height} ({aspect_ratio})")
            print(f"â±ï¸ é•·åº¦: {duration} ç§’")
            
            # å˜—è©¦ä½¿ç”¨ FFmpeg ç”ŸæˆçœŸå¯¦çš„MP4æª”æ¡ˆ
            if self._create_ffmpeg_video(mp4_path, width, height, duration, prompt):
                print(f"âœ… ä½¿ç”¨ FFmpeg å‰µå»ºæ¨™æº– MP4 æª”æ¡ˆ")
            else:
                # å›é€€åˆ°æ‰‹å‹•å‰µå»ºMP4çµæ§‹
                print("âš ï¸ FFmpeg ä¸å¯ç”¨ï¼Œä½¿ç”¨æ‰‹å‹• MP4 ç”Ÿæˆ")
                self._create_manual_mp4(mp4_path, width, height, duration)
            
            file_size = os.path.getsize(mp4_path)
            print(f"âœ… æ¨™æº– MP4 æª”æ¡ˆå‰µå»ºå®Œæˆ: {file_size:,} bytes ({file_size/1024/1024:.2f} MB)")
            
            return mp4_path
            
        except Exception as e:
            print(f"âŒ å‰µå»ºæ¨™æº–MP4æª”æ¡ˆæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            traceback.print_exc()
            
            # å‰µå»ºä¸€å€‹æœ€å°ä½†æœ‰æ•ˆçš„ MP4 æª”æ¡ˆ
            self._create_minimal_mp4(mp4_path, width, height, duration)
            return mp4_path
    
    def _create_ffmpeg_video(self, output_path: str, width: int, height: int, duration: int, prompt: str) -> bool:
        """ä½¿ç”¨ FFmpeg å‰µå»ºçœŸå¯¦çš„ MP4 å½±ç‰‡"""
        try:
            # åŸºæœ¬çš„ FFmpeg å‘½ä»¤ä¾†å‰µå»ºå½©è‰²å½±ç‰‡
            cmd = [
                'ffmpeg', '-y',  # è¦†è“‹è¼¸å‡ºæª”æ¡ˆ
                '-f', 'lavfi',
                '-i', f'color=c=blue:size={width}x{height}:duration={duration}:rate=30',
                '-c:v', 'libx264',
                '-pix_fmt', 'yuv420p',
                '-preset', 'fast',
                output_path
            ]
            
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=30)
            
            if result.returncode == 0:
                return True
            else:
                print(f"FFmpeg éŒ¯èª¤: {result.stderr}")
                return False
                
        except subprocess.TimeoutExpired:
            print("FFmpeg åŸ·è¡Œè¶…æ™‚")
            return False
        except FileNotFoundError:
            print("FFmpeg æœªå®‰è£æˆ–ä¸åœ¨ PATH ä¸­")
            return False
        except Exception as e:
            print(f"FFmpeg åŸ·è¡ŒéŒ¯èª¤: {e}")
            return False
    
    def _create_manual_mp4(self, mp4_path: str, width: int, height: int, duration: int) -> None:
        """æ‰‹å‹•å‰µå»º MP4 æª”æ¡ˆçµæ§‹"""
        import struct
        
        print("ğŸ”§ æ‰‹å‹•å‰µå»º MP4 æª”æ¡ˆçµæ§‹")
        
        with open(mp4_path, 'wb') as f:
            # ftyp box (æª”æ¡ˆé¡å‹)
            ftyp_data = b'mp42' + struct.pack('>I', 0) + b'mp42' + b'isom' + b'avc1'
            self._write_box(f, b'ftyp', ftyp_data)
            
            # moov box (å½±ç‰‡å…ƒæ•¸æ“š)
            total_frames = duration * 30  # 30 FPS
            moov_data = self._create_moov_data(width, height, duration, total_frames)
            self._write_box(f, b'moov', moov_data)
            
            # mdat box (åª’é«”æ•¸æ“š)
            mdat_data = self._create_media_data(total_frames)
            self._write_box(f, b'mdat', mdat_data)
    
    def _write_box(self, f, box_type: bytes, data: bytes):
        """å¯«å…¥ MP4 box"""
        size = len(data) + 8
        f.write(struct.pack('>I', size))
        f.write(box_type)
        f.write(data)
    
    def _create_moov_data(self, width: int, height: int, duration: int, total_frames: int) -> bytes:
        """å‰µå»º moov box æ•¸æ“š"""
        import struct
        from io import BytesIO
        
        moov_buffer = BytesIO()
        
        # mvhd (movie header)
        mvhd_data = struct.pack('>I', 0)  # version + flags
        mvhd_data += struct.pack('>I', 0)  # creation time
        mvhd_data += struct.pack('>I', 0)  # modification time
        mvhd_data += struct.pack('>I', 1000)  # timescale
        mvhd_data += struct.pack('>I', duration * 1000)  # duration
        mvhd_data += struct.pack('>I', 0x00010000)  # rate
        mvhd_data += struct.pack('>H', 0x0100)  # volume
        mvhd_data += b'\x00' * 10  # reserved
        
        # transformation matrix (identity)
        matrix = [0x00010000, 0, 0, 0, 0x00010000, 0, 0, 0, 0x40000000]
        for value in matrix:
            mvhd_data += struct.pack('>I', value)
        
        mvhd_data += struct.pack('>I', 0) * 6  # preview/poster/selection times
        mvhd_data += struct.pack('>I', 2)  # next track ID
        
        # å¯«å…¥ mvhd box
        mvhd_size = len(mvhd_data) + 8
        moov_buffer.write(struct.pack('>I', mvhd_size))
        moov_buffer.write(b'mvhd')
        moov_buffer.write(mvhd_data)
        
        result = moov_buffer.getvalue()
        moov_buffer.close()
        return result
    
    def _create_media_data(self, total_frames: int) -> bytes:
        """å‰µå»ºåª’é«”æ•¸æ“š"""
        frame_size = 2048  # æ¯å¹€2KB
        total_size = total_frames * frame_size
        
        print(f"ğŸï¸ å‰µå»ºåª’é«”æ•¸æ“š: {total_size:,} bytes")
        
        # å‰µå»ºæ¨¡æ“¬çš„ H.264 æ•¸æ“š
        data = bytearray()
        for i in range(total_size):
            data.append((i * 7 + 42) % 256)
        
        return bytes(data)
    
    def _create_minimal_mp4(self, mp4_path: str, width: int, height: int, duration: int) -> None:
        """å‰µå»ºæœ€å°çš„æœ‰æ•ˆMP4æª”æ¡ˆ"""
        import struct
        
        print("âš ï¸ å‰µå»ºæœ€å°æœ‰æ•ˆ MP4 æª”æ¡ˆ")
        
        with open(mp4_path, 'wb') as f:
            # æœ€å°çš„ ftyp box
            ftyp_data = b'mp42' + struct.pack('>I', 0) + b'mp42' + b'isom'
            self._write_box(f, b'ftyp', ftyp_data)
            
            # æœ€å°çš„ mdat box
            mdat_data = b'\x00' * (duration * 1024)  # æ¯ç§’1KB
            self._write_box(f, b'mdat', mdat_data)
    
    def get_supported_aspect_ratios(self) -> List[str]:
        """ç²å–æ”¯æ´çš„å½±ç‰‡æ¯”ä¾‹"""
        return ['16:9', '9:16']
    
    def get_supported_durations(self) -> List[int]:
        """ç²å–æ”¯æ´çš„å½±ç‰‡é•·åº¦"""
        return [5, 6, 7, 8]
    
    def get_model_info(self) -> Dict[str, Any]:
        """ç²å–æ¨¡å‹è³‡è¨Š"""
        return {
            'name': self.model_name,
            'version': 'Veo 2.0',
            'provider': 'Google GenAI',
            'supported_aspect_ratios': self.get_supported_aspect_ratios(),
            'supported_durations': self.get_supported_durations(),
            'max_prompt_length': 2000,
            'use_mock': self.use_mock
        }
    
    def calculate_cost(self, params: Dict[str, Any]) -> Dict[str, Any]:
        """è¨ˆç®—ç”Ÿæˆæˆæœ¬"""
        duration = params.get('duration', 5)
        aspect_ratio = params.get('aspectRatio', '16:9')
        
        # Veo 2 å®šåƒ¹ (æ ¹æ“šå®˜æ–¹æ–‡æª”)
        base_price = 2.50 if duration <= 5 else 5.00
        
        return {
            'total_cost': base_price,
            'currency': 'USD',
            'breakdown': {
                'base_cost': base_price,
                'duration': duration,
                'aspect_ratio': aspect_ratio,
                'model': self.model_name
            }
        }
    
    def _print_quota_solutions(self):
        """æ‰“å°é…é¡è§£æ±ºæ–¹æ¡ˆ"""
        print("ğŸ’¡ é…é¡è¶…é™è§£æ±ºæ–¹æ¡ˆ:")
        print("   1. æª¢æŸ¥ Google Cloud Console ä¸­çš„é…é¡ä½¿ç”¨æƒ…æ³")
        print("      https://console.cloud.google.com/iam-admin/quotas")
        print("   2. ç”³è«‹å¢åŠ é…é¡ï¼š")
        print("      https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai")
        print("   3. ç­‰å¾…é…é¡é‡ç½®ï¼ˆé€šå¸¸æ¯åˆ†é˜é‡ç½®ï¼‰")
        print("   4. è€ƒæ…®ä»¥ä¸‹æ›¿ä»£æ–¹æ¡ˆ:")
        print("      - æ¸›å°‘ç”Ÿæˆé »ç‡")
        print("      - ä½¿ç”¨è¼ƒçŸ­çš„å½±ç‰‡æ™‚é•·")
        print("      - åˆ†æ‰¹è™•ç†è«‹æ±‚")
        print("      - å‡ç´šåˆ°ä»˜è²»å¸³æˆ¶ä»¥ç²å¾—æ›´é«˜é…é¡")

# æ¸¬è©¦å‡½æ•¸
def test_veo_service():
    """æ¸¬è©¦ Veo æœå‹™"""
    try:
        service = VeoService()
        
        # æ¸¬è©¦åƒæ•¸
        test_params = {
            'prompt': 'A cute kitten playing in a sunny garden',
            'aspectRatio': '16:9',
            'duration': 5,
            'personGeneration': 'disallow',
            'style': 'cinematic'
        }
        
        print("ğŸ§ª æ¸¬è©¦ Veo æœå‹™...")
        result = service.generate_videos(test_params)
        
        if result['success']:
            print("âœ… Veo æœå‹™æ¸¬è©¦æˆåŠŸ")
            print(f"   ç”Ÿæˆå½±ç‰‡æ•¸é‡: {result['total_count']}")
            print(f"   æ¨¡æ“¬æ¨¡å¼: {result.get('mock_mode', False)}")
            
            # æª¢æŸ¥ç”Ÿæˆçš„æª”æ¡ˆ
            for video in result['videos']:
                filepath = video['path']
                if os.path.exists(filepath):
                    file_size = os.path.getsize(filepath)
                    print(f"   æª”æ¡ˆå¤§å°: {file_size:,} bytes ({file_size/1024/1024:.2f} MB)")
        else:
            print(f"âŒ Veo æœå‹™æ¸¬è©¦å¤±æ•—: {result['error']}")
            
    except Exception as e:
        print(f"âŒ Veo æœå‹™æ¸¬è©¦éŒ¯èª¤: {e}")
        traceback.print_exc()

if __name__ == "__main__":
    test_veo_service() 